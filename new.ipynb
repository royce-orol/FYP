{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this at the top of your modeling section\n",
    "results = []\n",
    "\n",
    "def store_result(branch, model_name, feature_strategy, tuning, accuracy, precision, recall, f1):\n",
    "    results.append({\n",
    "        'Branch': branch,\n",
    "        'Model': model_name,\n",
    "        'Feature Selection': feature_strategy,\n",
    "        'Tuned': tuning,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "/var/folders/4z/pg_w4ml11xvdtzv8kb6z7w7c0000gn/T/ipykernel_14285/1686993148.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"nyc.csv\")  \n",
    "# Drop rows where AIDS_diagnosed is missing\n",
    "df = df.dropna(subset=[\"AIDS_diagnosed\"])\n",
    "\n",
    "# Replace 'None' with np.nan in Concurrent_diagnosed\n",
    "df['Concurrent_diagnosed'] = df['Concurrent_diagnosed'].replace('None', np.nan)\n",
    "df['Concurrent_diagnosed'] = df['Concurrent_diagnosed'].fillna('No Other Disease')\n",
    "\n",
    "# Fill missing or None values (mode for categorical, median for numeric)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col].replace(\"None\", np.nan, inplace=True)\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Convert boolean-like columns to 0/1\n",
    "bool_columns = ['HIV_diagnosed', 'AIDS_diagnosed', 'Linked_to_Care_3mo', 'Death_Status']\n",
    "for col in bool_columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].map({'No': 0, 'Yes': 1, 'Alive': 0, 'Deceased': 1, True: 1, False: 0})\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Outlier detection (optional)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "iso = IsolationForest(contamination=0.01, random_state=42)\n",
    "outliers = iso.fit_predict(df.select_dtypes(include=np.number))\n",
    "df = df[outliers == 1]\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop('AIDS_diagnosed', axis=1)\n",
    "y = df['AIDS_diagnosed']\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_columns = X.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in cat_columns:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# === Handle class imbalance using SMOTE ===\n",
    "smote = SMOTE(random_state=42)\n",
    "X_bal, y_bal = smote.fit_resample(X, y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Standard scaling for most models\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_bal)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "# MinMax scaling for chi-square feature selection\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_bal_minmax = minmax_scaler.fit_transform(X_bal)\n",
    "X_minmax = pd.DataFrame(X_bal_minmax, columns=X.columns)\n",
    "X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax = train_test_split(X_minmax, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_bal)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"✅ Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRANCH A : TRAIN ON 80% TEST ON 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branch A: 80% train, 20% test\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = train_test_split(X_bal, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standard scaling for most models\n",
    "scaler_A = StandardScaler()\n",
    "X_train_A_scaled = scaler_A.fit_transform(X_train_A)\n",
    "X_test_A_scaled = scaler_A.transform(X_test_A)\n",
    "X_train_A_scaled = pd.DataFrame(X_train_A_scaled, columns=X.columns)\n",
    "X_test_A_scaled = pd.DataFrame(X_test_A_scaled, columns=X.columns)\n",
    "\n",
    "# MinMax scaling for chi-square\n",
    "minmax_scaler_A = MinMaxScaler()\n",
    "X_train_A_minmax = minmax_scaler_A.fit_transform(X_train_A)\n",
    "X_test_A_minmax = minmax_scaler_A.transform(X_test_A)\n",
    "X_train_A_minmax = pd.DataFrame(X_train_A_minmax, columns=X.columns)\n",
    "X_test_A_minmax = pd.DataFrame(X_test_A_minmax, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRANCH B : TRAIN ON 20% TEST ON 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branch B: 20% train, 80% test\n",
    "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X_bal, y_bal, test_size=0.8, random_state=42)\n",
    "\n",
    "# Standard scaling for most models\n",
    "scaler_B = StandardScaler()\n",
    "X_train_B_scaled = scaler_B.fit_transform(X_train_B)\n",
    "X_test_B_scaled = scaler_B.transform(X_test_B)\n",
    "X_train_B_scaled = pd.DataFrame(X_train_B_scaled, columns=X.columns)\n",
    "X_test_B_scaled = pd.DataFrame(X_test_B_scaled, columns=X.columns)\n",
    "\n",
    "# MinMax scaling for chi-square\n",
    "minmax_scaler_B = MinMaxScaler()\n",
    "X_train_B_minmax = minmax_scaler_B.fit_transform(X_train_B)\n",
    "X_test_B_minmax = minmax_scaler_B.transform(X_test_B)\n",
    "X_train_B_minmax = pd.DataFrame(X_train_B_minmax, columns=X.columns)\n",
    "X_test_B_minmax = pd.DataFrame(X_test_B_minmax, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-square (use MinMax scaled data)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "k = 10  # or any number you prefer\n",
    "\n",
    "# Branch A\n",
    "selector_A = SelectKBest(score_func=chi2, k=k)\n",
    "X_train_A_chi = selector_A.fit_transform(X_train_A_minmax, y_train_A)\n",
    "X_test_A_chi = selector_A.transform(X_test_A_minmax)\n",
    "\n",
    "# Branch B\n",
    "selector_B = SelectKBest(score_func=chi2, k=k)\n",
    "X_train_B_chi = selector_B.fit_transform(X_train_B_minmax, y_train_B)\n",
    "X_test_B_chi = selector_B.transform(X_test_B_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haziqzairul/.local/share/virtualenvs/datamining-5l9yRiuj/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/haziqzairul/.local/share/virtualenvs/datamining-5l9yRiuj/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3046: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/haziqzairul/.local/share/virtualenvs/datamining-5l9yRiuj/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/haziqzairul/.local/share/virtualenvs/datamining-5l9yRiuj/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3046: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# Correlation (Use Standard scaled data)\n",
    "\n",
    "correlations_A = X_train_A_scaled.corrwith(pd.Series(y_train_A)).abs()\n",
    "top_k_A = correlations_A.sort_values(ascending=False).head(k).index.tolist()\n",
    "X_train_A_corr = X_train_A_scaled[top_k_A]\n",
    "X_test_A_corr = X_test_A_scaled[top_k_A]\n",
    "\n",
    "# Branch B\n",
    "correlations_B = X_train_B_scaled.corrwith(pd.Series(y_train_B)).abs()\n",
    "top_k_B = correlations_B.sort_values(ascending=False).head(k).index.tolist()\n",
    "X_train_B_corr = X_train_B_scaled[top_k_B]\n",
    "X_test_B_corr = X_test_B_scaled[top_k_B]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM BRANCH A (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch A (No Feature Selection, Not Tuned) Accuracy: 0.6902324461038178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.71      4154\n",
      "           1       0.72      0.62      0.67      4149\n",
      "\n",
      "    accuracy                           0.69      8303\n",
      "   macro avg       0.69      0.69      0.69      8303\n",
      "weighted avg       0.69      0.69      0.69      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM BRANCH A NO FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "svm_A = SVC(random_state=42)\n",
    "svm_A.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_svm_A = svm_A.predict(X_test_A_scaled)\n",
    "print(\"SVM Branch A (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A))\n",
    "print(classification_report(y_test_A, y_pred_svm_A))\n",
    "store_result('A','SVM', 'None', 'No', accuracy_score(y_test_A, y_pred_svm_A),\n",
    "             precision_score(y_test_A, y_pred_svm_A, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "svm_A_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_A_tuned.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_svm_A_tuned = svm_A_tuned.predict(X_test_A_scaled)\n",
    "print(\"SVM Branch A (No Feature Selection, Tuned) Best Params:\", svm_A_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_tuned))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_tuned))\n",
    "store_result('A','SVM', 'None', 'Yes', accuracy_score(y_test_A, y_pred_svm_A_tuned),\n",
    "             precision_score(y_test_A, y_pred_svm_A_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM BRANCH A CHI SQUARE FEATURE SELECTION\n",
    "# NOT TUNED\n",
    "\n",
    "svm_A_chi = SVC(random_state=42)\n",
    "svm_A_chi.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_svm_A_chi = svm_A_chi.predict(X_test_A_chi)\n",
    "print(\"SVM Branch A (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_chi))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_chi))\n",
    "store_result('A''SVM', 'Chi-square', 'No', accuracy_score(y_test_A, y_pred_svm_A_chi),\n",
    "             precision_score(y_test_A, y_pred_svm_A_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_chi, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "svm_A_chi_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_A_chi_tuned.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_svm_A_chi_tuned = svm_A_chi_tuned.predict(X_test_A_chi)\n",
    "print(\"SVM Branch A (Chi-square, Tuned) Best Params:\", svm_A_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_chi_tuned))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_chi_tuned))\n",
    "store_result('A','SVM', 'Chi-square', 'Yes', accuracy_score(y_test_A, y_pred_svm_A_chi_tuned),\n",
    "             precision_score(y_test_A, y_pred_svm_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_chi_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM BRANCH A CORRELATION FEATURE SELECTION\n",
    "# NOT TUNED\n",
    "svm_A_corr = SVC(random_state=42)\n",
    "svm_A_corr.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_svm_A_corr = svm_A_corr.predict(X_test_A_corr)\n",
    "print(\"SVM Branch A (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_corr))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_corr))\n",
    "store_result('A','SVM', 'Correlation', 'No', accuracy_score(y_test_A, y_pred_svm_A_corr),\n",
    "             precision_score(y_test_A, y_pred_svm_A_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_corr, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "svm_A_corr_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_A_corr_tuned.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_svm_A_corr_tuned = svm_A_corr_tuned.predict(X_test_A_corr)\n",
    "print(\"SVM Branch A (Correlation, Tuned) Best Params:\", svm_A_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_corr_tuned))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_corr_tuned))\n",
    "store_result('A','SVM', 'Correlation', 'Yes', accuracy_score(y_test_A, y_pred_svm_A_corr_tuned),\n",
    "             precision_score(y_test_A, y_pred_svm_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_corr_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM BRANCH B (20/80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "svm_B = SVC(random_state=42)\n",
    "svm_B.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_svm_B = svm_B.predict(X_test_B_scaled)\n",
    "print(\"SVM Branch B (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B))\n",
    "print(classification_report(y_test_B, y_pred_svm_B))\n",
    "store_result('B','SVM', 'None', 'No', accuracy_score(y_test_B, y_pred_svm_B),\n",
    "             precision_score(y_test_B, y_pred_svm_B, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "svm_B_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_B_tuned.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_svm_B_tuned = svm_B_tuned.predict(X_test_B_scaled)\n",
    "print(\"SVM Branch B (No Feature Selection, Tuned) Best Params:\", svm_B_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_tuned))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_tuned))\n",
    "store_result('B','SVM', 'None', 'Yes', accuracy_score(y_test_B, y_pred_svm_B_tuned),\n",
    "             precision_score(y_test_B, y_pred_svm_B_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHI SQUARE FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "\n",
    "svm_B_chi = SVC(random_state=42)\n",
    "svm_B_chi.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_svm_B_chi = svm_B_chi.predict(X_test_B_chi)\n",
    "print(\"SVM Branch B (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_chi))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_chi))\n",
    "store_result('B','SVM', 'Chi-square', 'No', accuracy_score(y_test_B, y_pred_svm_B_chi),\n",
    "             precision_score(y_test_B, y_pred_svm_B_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_chi, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "svm_B_chi_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_B_chi_tuned.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_svm_B_chi_tuned = svm_B_chi_tuned.predict(X_test_B_chi)\n",
    "print(\"SVM Branch B (Chi-square, Tuned) Best Params:\", svm_B_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_chi_tuned))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_chi_tuned))\n",
    "store_result('B','SVM', 'Chi-square', 'Yes', accuracy_score(y_test_B, y_pred_svm_B_chi_tuned),\n",
    "             precision_score(y_test_B, y_pred_svm_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_chi_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORRELATION FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "svm_B_corr = SVC(random_state=42)\n",
    "svm_B_corr.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_svm_B_corr = svm_B_corr.predict(X_test_B_corr)\n",
    "print(\"SVM Branch B (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_corr))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_corr))\n",
    "store_result('B','SVM', 'Correlation', 'No', accuracy_score(y_test_B, y_pred_svm_B_corr),\n",
    "             precision_score(y_test_B, y_pred_svm_B_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_corr, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "svm_B_corr_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_B_corr_tuned.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_svm_B_corr_tuned = svm_B_corr_tuned.predict(X_test_B_corr)\n",
    "print(\"SVM Branch B (Correlation, Tuned) Best Params:\", svm_B_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_corr_tuned))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_corr_tuned))\n",
    "store_result('B','SVM', 'Correlation', 'Yes', accuracy_score(y_test_B, y_pred_svm_B_corr_tuned),\n",
    "             precision_score(y_test_B, y_pred_svm_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_corr_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE BRANCH A (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO FEATURE SELECTION\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# NOT TUNED\n",
    "dt_A = DecisionTreeClassifier(random_state=42)\n",
    "dt_A.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_dt_A = dt_A.predict(X_test_A_scaled)\n",
    "print(\"Decision Tree Branch A (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A))\n",
    "print(classification_report(y_test_A, y_pred_dt_A))\n",
    "store_result('Decision Tree', 'None', 'No', accuracy_score(y_test_A, y_pred_dt_A),\n",
    "             precision_score(y_test_A, y_pred_dt_A, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "param_grid_dt = {'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5, 10]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dt_A_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_A_tuned.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_dt_A_tuned = dt_A_tuned.predict(X_test_A_scaled)\n",
    "print(\"Decision Tree Branch A (No Feature Selection, Tuned) Best Params:\", dt_A_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_tuned))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_tuned))\n",
    "store_result('A','Decision Tree', 'None', 'Yes', accuracy_score(y_test_A, y_pred_dt_A_tuned),\n",
    "             precision_score(y_test_A, y_pred_dt_A_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CHI SQUARE FEATURE SELECTION\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dt_A_chi \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m dt_A_chi\u001b[38;5;241m.\u001b[39mfit(X_train_A_chi, y_train_A)\n\u001b[1;32m      5\u001b[0m y_pred_dt_A_chi \u001b[38;5;241m=\u001b[39m dt_A_chi\u001b[38;5;241m.\u001b[39mpredict(X_test_A_chi)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# CHI SQUARE FEATURE SELECTION\n",
    "\n",
    "#NOT TUNED\n",
    "dt_A_chi = DecisionTreeClassifier(random_state=42)\n",
    "dt_A_chi.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_dt_A_chi = dt_A_chi.predict(X_test_A_chi)\n",
    "print(\"Decision Tree Branch A (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_chi))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_chi))\n",
    "store_result('Decision Tree', 'Chi-square', 'No', accuracy_score(y_test_A, y_pred_dt_A_chi),\n",
    "             precision_score(y_test_A, y_pred_dt_A_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_chi, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "dt_A_chi_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_A_chi_tuned.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_dt_A_chi_tuned = dt_A_chi_tuned.predict(X_test_A_chi)\n",
    "print(\"Decision Tree Branch A (Chi-square, Tuned) Best Params:\", dt_A_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_chi_tuned))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_chi_tuned))\n",
    "store_result('A','Decision Tree', 'Chi-square', 'Yes', accuracy_score(y_test_A, y_pred_dt_A_chi_tuned),\n",
    "             precision_score(y_test_A, y_pred_dt_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_chi_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORRELATION FEATURE SELECTION\n",
    "# Not Tuned\n",
    "dt_A_corr = DecisionTreeClassifier(random_state=42)\n",
    "dt_A_corr.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_dt_A_corr = dt_A_corr.predict(X_test_A_corr)\n",
    "print(\"Decision Tree Branch A (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_corr))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_corr))\n",
    "store_result('A','Decision Tree', 'Correlation', 'No', accuracy_score(y_test_A, y_pred_dt_A_corr),\n",
    "             precision_score(y_test_A, y_pred_dt_A_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_corr, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "dt_A_corr_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_A_corr_tuned.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_dt_A_corr_tuned = dt_A_corr_tuned.predict(X_test_A_corr)\n",
    "print(\"Decision Tree Branch A (Correlation, Tuned) Best Params:\", dt_A_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_corr_tuned))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_corr_tuned))\n",
    "store_result('Decision Tree', 'Correlation', 'Yes', accuracy_score(y_test_A, y_pred_dt_A_corr_tuned),\n",
    "             precision_score(y_test_A, y_pred_dt_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_corr_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE BRANCH B (20/80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "\n",
    "dt_B = DecisionTreeClassifier(random_state=42)\n",
    "dt_B.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_dt_B = dt_B.predict(X_test_B_scaled)\n",
    "print(\"Decision Tree Branch B (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B))\n",
    "print(classification_report(y_test_B, y_pred_dt_B))\n",
    "store_result('B','Decision Tree', 'None', 'No', accuracy_score(y_test_B, y_pred_dt_B),\n",
    "             precision_score(y_test_B, y_pred_dt_B, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "dt_B_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_B_tuned.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_dt_B_tuned = dt_B_tuned.predict(X_test_B_scaled)\n",
    "print(\"Decision Tree Branch B (No Feature Selection, Tuned) Best Params:\", dt_B_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_tuned))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_tuned))\n",
    "store_result('B','Decision Tree', 'None', 'Yes', accuracy_score(y_test_B, y_pred_dt_B_tuned),\n",
    "             precision_score(y_test_B, y_pred_dt_B_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHI SQUARE FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "dt_B_chi = DecisionTreeClassifier(random_state=42)\n",
    "dt_B_chi.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_dt_B_chi = dt_B_chi.predict(X_test_B_chi)\n",
    "print(\"Decision Tree Branch B (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_chi))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_chi))\n",
    "store_result('B','Decision Tree', 'Chi-square', 'No', accuracy_score(y_test_B, y_pred_dt_B_chi),\n",
    "             precision_score(y_test_B, y_pred_dt_B_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_chi, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "dt_B_chi_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_B_chi_tuned.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_dt_B_chi_tuned = dt_B_chi_tuned.predict(X_test_B_chi)\n",
    "print(\"Decision Tree Branch B (Chi-square, Tuned) Best Params:\", dt_B_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_chi_tuned))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_chi_tuned))\n",
    "store_result('B','Decision Tree', 'Chi-square', 'Yes', accuracy_score(y_test_B, y_pred_dt_B_chi_tuned),\n",
    "             precision_score(y_test_B, y_pred_dt_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_chi_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORRELATION FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "dt_B_corr = DecisionTreeClassifier(random_state=42)\n",
    "dt_B_corr.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_dt_B_corr = dt_B_corr.predict(X_test_B_corr)\n",
    "print(\"Decision Tree Branch B (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_corr))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_corr))\n",
    "store_result('B','Decision Tree', 'Correlation', 'No', accuracy_score(y_test_B, y_pred_dt_B_corr),\n",
    "             precision_score(y_test_B, y_pred_dt_B_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_corr, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "dt_B_corr_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_B_corr_tuned.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_dt_B_corr_tuned = dt_B_corr_tuned.predict(X_test_B_corr)\n",
    "print(\"Decision Tree Branch B (Correlation, Tuned) Best Params:\", dt_B_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_corr_tuned))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_corr_tuned))\n",
    "store_result('B','Decision Tree', 'Correlation', 'Yes', accuracy_score(y_test_B, y_pred_dt_B_corr_tuned),\n",
    "             precision_score(y_test_B, y_pred_dt_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_corr_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST BRANCH A (80/20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO FEATURE SELECTION\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Not Tuned\n",
    "xgb_A = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_A.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_xgb_A = xgb_A.predict(X_test_A_scaled)\n",
    "print(\"XGBoost Branch A (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A))\n",
    "store_result('A','XGBoost', 'None', 'No', accuracy_score(y_test_A, y_pred_xgb_A),\n",
    "             precision_score(y_test_A, y_pred_xgb_A, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "param_grid_xgb = {'max_depth': [3, 5, 10], 'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [100, 200]}\n",
    "xgb_A_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_A_tuned.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_xgb_A_tuned = xgb_A_tuned.predict(X_test_A_scaled)\n",
    "print(\"XGBoost Branch A (No Feature Selection, Tuned) Best Params:\", xgb_A_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_tuned))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_tuned))\n",
    "store_result('A','XGBoost', 'None', 'Yes', accuracy_score(y_test_A, y_pred_xgb_A_tuned),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHI SQUARE FEATURE SELECTION\n",
    "\n",
    "# Not Tuned\n",
    "xgb_A_chi = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_A_chi.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_xgb_A_chi = xgb_A_chi.predict(X_test_A_chi)\n",
    "print(\"XGBoost Branch A (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_chi))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_chi))\n",
    "store_result('XGBoost', 'Chi-square', 'No', accuracy_score(y_test_A, y_pred_xgb_A_chi),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_chi, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "xgb_A_chi_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_A_chi_tuned.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_xgb_A_chi_tuned = xgb_A_chi_tuned.predict(X_test_A_chi)\n",
    "print(\"XGBoost Branch A (Chi-square, Tuned) Best Params:\", xgb_A_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_chi_tuned))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_chi_tuned))\n",
    "store_result('XGBoost', 'Chi-square', 'Yes', accuracy_score(y_test_A, y_pred_xgb_A_chi_tuned),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_chi_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORRELATION FEATURE SELECTION\n",
    "# Not Tuned\n",
    "xgb_A_corr = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_A_corr.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_xgb_A_corr = xgb_A_corr.predict(X_test_A_corr)\n",
    "print(\"XGBoost Branch A (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_corr))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_corr))\n",
    "store_result('XGBoost', 'Correlation', 'No', accuracy_score(y_test_A, y_pred_xgb_A_corr),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_corr, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "xgb_A_corr_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_A_corr_tuned.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_xgb_A_corr_tuned = xgb_A_corr_tuned.predict(X_test_A_corr)\n",
    "print(\"XGBoost Branch A (Correlation, Tuned) Best Params:\", xgb_A_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_corr_tuned))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_corr_tuned))\n",
    "store_result('XGBoost', 'Correlation', 'Yes', accuracy_score(y_test_A, y_pred_xgb_A_corr_tuned),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_corr_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST BRANCH B (20/80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SELECTION\n",
    "#NOT TUNED \n",
    "xgb_B = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_B.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_xgb_B = xgb_B.predict(X_test_B_scaled)\n",
    "print(\"XGBoost Branch B (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B))\n",
    "store_result('B','XGBoost', 'None', 'No', accuracy_score(y_test_B, y_pred_xgb_B),\n",
    "             precision_score(y_test_B, y_pred_xgb_B, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "xgb_B_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_B_tuned.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_xgb_B_tuned = xgb_B_tuned.predict(X_test_B_scaled)\n",
    "print(\"XGBoost Branch B (No Feature Selection, Tuned) Best Params:\", xgb_B_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_tuned))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_tuned))\n",
    "store_result('B','XGBoost', 'None', 'Yes', accuracy_score(y_test_B, y_pred_xgb_B_tuned),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHI SQUARE FEATURE SELECTION\n",
    "# NOT TUNED\n",
    "\n",
    "xgb_B_chi = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_B_chi.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_xgb_B_chi = xgb_B_chi.predict(X_test_B_chi)\n",
    "print(\"XGBoost Branch B (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_chi))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_chi))\n",
    "store_result('B','XGBoost', 'Chi-square', 'No', accuracy_score(y_test_B, y_pred_xgb_B_chi),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_chi, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED\n",
    "xgb_B_chi_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_B_chi_tuned.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_xgb_B_chi_tuned = xgb_B_chi_tuned.predict(X_test_B_chi)\n",
    "print(\"XGBoost Branch B (Chi-square, Tuned) Best Params:\", xgb_B_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_chi_tuned))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_chi_tuned))\n",
    "store_result('B','XGBoost', 'Chi-square', 'Yes', accuracy_score(y_test_B, y_pred_xgb_B_chi_tuned),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_chi_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION FEATURE SELECTION\n",
    "# NOT TUNED\n",
    "xgb_B_corr = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_B_corr.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_xgb_B_corr = xgb_B_corr.predict(X_test_B_corr)\n",
    "print(\"XGBoost Branch B (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_corr))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_corr))\n",
    "store_result('B','XGBoost', 'Correlation', 'No', accuracy_score(y_test_B, y_pred_xgb_B_corr),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_corr, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNED\n",
    "xgb_B_corr_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_B_corr_tuned.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_xgb_B_corr_tuned = xgb_B_corr_tuned.predict(X_test_B_corr)\n",
    "print(\"XGBoost Branch B (Correlation, Tuned) Best Params:\", xgb_B_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_corr_tuned))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_corr_tuned))\n",
    "store_result('B','XGBoost', 'Correlation', 'Yes', accuracy_score(y_test_B, y_pred_xgb_B_corr_tuned),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_corr_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION COMPARISON TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame from results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort for readability\n",
    "results_df = results_df.sort_values(by=['Branch', 'Model', 'Feature Selection', 'Tuned'])\n",
    "\n",
    "# Display the table\n",
    "display(results_df)\n",
    "\n",
    "# Optionally, highlight the best accuracy and F1-score in each branch/model\n",
    "def highlight_best(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: lightgreen' if v else '' for v in is_max]\n",
    "\n",
    "# Highlight best per Branch+Model group\n",
    "styled = results_df.style\n",
    "for (branch, model), group in results_df.groupby(['Branch', 'Model']):\n",
    "    idx = group['Accuracy'].idxmax()\n",
    "    styled = styled.apply(lambda x: ['background-color: lightgreen' if i == idx else '' for i in x.index], subset=['Accuracy'])\n",
    "    idx_f1 = group['F1-score'].idxmax()\n",
    "    styled = styled.apply(lambda x: ['background-color: lightblue' if i == idx_f1 else '' for i in x.index], subset=['F1-score'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining-5l9yRiuj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
