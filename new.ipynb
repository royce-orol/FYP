{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this at the top of your modeling section\n",
    "results = []\n",
    "\n",
    "def store_result(branch, model_name, feature_strategy, tuning, accuracy, precision, recall, f1):\n",
    "    results.append({\n",
    "        'Branch': branch,\n",
    "        'Model': model_name,\n",
    "        'Feature Selection': feature_strategy,\n",
    "        'Tuned': tuning,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(\"None\", np.nan, inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7572\\3534736376.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"nyc.csv\")  \n",
    "# Drop rows where AIDS_diagnosed is missing\n",
    "df = df.dropna(subset=[\"AIDS_diagnosed\"])\n",
    "\n",
    "# Replace 'None' with np.nan in Concurrent_diagnosed\n",
    "df['Concurrent_diagnosed'] = df['Concurrent_diagnosed'].replace('None', np.nan)\n",
    "df['Concurrent_diagnosed'] = df['Concurrent_diagnosed'].fillna('No Other Disease')\n",
    "\n",
    "# Fill missing or None values (mode for categorical, median for numeric)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col].replace(\"None\", np.nan, inplace=True)\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Convert boolean-like columns to 0/1\n",
    "bool_columns = ['HIV_diagnosed', 'AIDS_diagnosed', 'Linked_to_Care_3mo', 'Death_Status']\n",
    "for col in bool_columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].map({'No': 0, 'Yes': 1, 'Alive': 0, 'Deceased': 1, True: 1, False: 0})\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Outlier detection (optional)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "iso = IsolationForest(contamination=0.01, random_state=42)\n",
    "outliers = iso.fit_predict(df.select_dtypes(include=np.number))\n",
    "df = df[outliers == 1]\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop('AIDS_diagnosed', axis=1)\n",
    "y = df['AIDS_diagnosed']\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_columns = X.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in cat_columns:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# === Handle class imbalance using SMOTE ===\n",
    "smote = SMOTE(random_state=42)\n",
    "X_bal, y_bal = smote.fit_resample(X, y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Standard scaling for most models\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_bal)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "# MinMax scaling for chi-square feature selection\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_bal_minmax = minmax_scaler.fit_transform(X_bal)\n",
    "X_minmax = pd.DataFrame(X_bal_minmax, columns=X.columns)\n",
    "X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax = train_test_split(X_minmax, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_bal)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"✅ Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRANCH A : TRAIN ON 80% TEST ON 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branch A: 80% train, 20% test\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = train_test_split(X_bal, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standard scaling for most models\n",
    "scaler_A = StandardScaler()\n",
    "X_train_A_scaled = scaler_A.fit_transform(X_train_A)\n",
    "X_test_A_scaled = scaler_A.transform(X_test_A)\n",
    "X_train_A_scaled = pd.DataFrame(X_train_A_scaled, columns=X.columns)\n",
    "X_test_A_scaled = pd.DataFrame(X_test_A_scaled, columns=X.columns)\n",
    "\n",
    "# MinMax scaling for chi-square\n",
    "minmax_scaler_A = MinMaxScaler()\n",
    "X_train_A_minmax = minmax_scaler_A.fit_transform(X_train_A)\n",
    "X_test_A_minmax = minmax_scaler_A.transform(X_test_A)\n",
    "X_train_A_minmax = pd.DataFrame(X_train_A_minmax, columns=X.columns)\n",
    "X_test_A_minmax = pd.DataFrame(X_test_A_minmax, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRANCH B : TRAIN ON 20% TEST ON 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branch B: 20% train, 80% test\n",
    "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X_bal, y_bal, test_size=0.8, random_state=42)\n",
    "\n",
    "# Standard scaling for most models\n",
    "scaler_B = StandardScaler()\n",
    "X_train_B_scaled = scaler_B.fit_transform(X_train_B)\n",
    "X_test_B_scaled = scaler_B.transform(X_test_B)\n",
    "X_train_B_scaled = pd.DataFrame(X_train_B_scaled, columns=X.columns)\n",
    "X_test_B_scaled = pd.DataFrame(X_test_B_scaled, columns=X.columns)\n",
    "\n",
    "# MinMax scaling for chi-square\n",
    "minmax_scaler_B = MinMaxScaler()\n",
    "X_train_B_minmax = minmax_scaler_B.fit_transform(X_train_B)\n",
    "X_test_B_minmax = minmax_scaler_B.transform(X_test_B)\n",
    "X_train_B_minmax = pd.DataFrame(X_train_B_minmax, columns=X.columns)\n",
    "X_test_B_minmax = pd.DataFrame(X_test_B_minmax, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-square (use MinMax scaled data)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "k = 10  # or any number you prefer\n",
    "\n",
    "# Branch A\n",
    "selector_A = SelectKBest(score_func=chi2, k=k)\n",
    "X_train_A_chi = selector_A.fit_transform(X_train_A_minmax, y_train_A)\n",
    "X_test_A_chi = selector_A.transform(X_test_A_minmax)\n",
    "\n",
    "# Branch B\n",
    "selector_B = SelectKBest(score_func=chi2, k=k)\n",
    "X_train_B_chi = selector_B.fit_transform(X_train_B_minmax, y_train_B)\n",
    "X_test_B_chi = selector_B.transform(X_test_B_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3046: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3046: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# Correlation (Use Standard scaled data)\n",
    "\n",
    "correlations_A = X_train_A_scaled.corrwith(pd.Series(y_train_A)).abs()\n",
    "top_k_A = correlations_A.sort_values(ascending=False).head(k).index.tolist()\n",
    "X_train_A_corr = X_train_A_scaled[top_k_A]\n",
    "X_test_A_corr = X_test_A_scaled[top_k_A]\n",
    "\n",
    "# Branch B\n",
    "correlations_B = X_train_B_scaled.corrwith(pd.Series(y_train_B)).abs()\n",
    "top_k_B = correlations_B.sort_values(ascending=False).head(k).index.tolist()\n",
    "X_train_B_corr = X_train_B_scaled[top_k_B]\n",
    "X_test_B_corr = X_test_B_scaled[top_k_B]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM BRANCH A (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch A (No Feature Selection, Not Tuned) Accuracy: 0.6937251595808743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.71      4154\n",
      "           1       0.73      0.62      0.67      4149\n",
      "\n",
      "    accuracy                           0.69      8303\n",
      "   macro avg       0.70      0.69      0.69      8303\n",
      "weighted avg       0.70      0.69      0.69      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM BRANCH A NO FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "svm_A = SVC(random_state=42)\n",
    "svm_A.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_svm_A = svm_A.predict(X_test_A_scaled)\n",
    "print(\"SVM Branch A (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A))\n",
    "print(classification_report(y_test_A, y_pred_svm_A))\n",
    "store_result('A','SVM', 'None', 'No', accuracy_score(y_test_A, y_pred_svm_A),\n",
    "             precision_score(y_test_A, y_pred_svm_A, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION ARRAY SETUP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3046: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Chi-square feature selection\n",
    "\n",
    "k = 10  # or any number you prefer\n",
    "selector = SelectKBest(score_func=chi2, k=k)\n",
    "X_train_chi = selector.fit_transform(X_train_minmax, y_train_minmax)\n",
    "X_test_chi = selector.transform(X_test_minmax)\n",
    "\n",
    "\n",
    "# Correlation-based feature selection\n",
    "import numpy as np\n",
    "correlations = pd.DataFrame(X_train).corrwith(pd.Series(y_train)).abs()\n",
    "top_k = correlations.sort_values(ascending=False).head(k).index\n",
    "X_train_corr = X_train[top_k]\n",
    "X_test_corr = X_test[top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch A (No Feature Selection, Tuned) Best Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.6937251595808743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.71      4154\n",
      "           1       0.73      0.62      0.67      4149\n",
      "\n",
      "    accuracy                           0.69      8303\n",
      "   macro avg       0.70      0.69      0.69      8303\n",
      "weighted avg       0.70      0.69      0.69      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "svm_A_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_A_tuned.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_svm_A_tuned = svm_A_tuned.predict(X_test_A_scaled)\n",
    "print(\"SVM Branch A (No Feature Selection, Tuned) Best Params:\", svm_A_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_tuned))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_tuned))\n",
    "store_result('A','SVM', 'None', 'Yes', accuracy_score(y_test_A, y_pred_svm_A_tuned),\n",
    "             precision_score(y_test_A, y_pred_svm_A_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch A (Chi-square, Not Tuned) Accuracy: 0.6583162712272672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      4154\n",
      "           1       0.67      0.62      0.64      4149\n",
      "\n",
      "    accuracy                           0.66      8303\n",
      "   macro avg       0.66      0.66      0.66      8303\n",
      "weighted avg       0.66      0.66      0.66      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM BRANCH A CHI SQUARE FEATURE SELECTION\n",
    "# NOT TUNED\n",
    "\n",
    "svm_A_chi = SVC(random_state=42)\n",
    "svm_A_chi.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_svm_A_chi = svm_A_chi.predict(X_test_A_chi)\n",
    "print(\"SVM Branch A (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_chi))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_chi))\n",
    "store_result('A','SVM', 'Chi-square', 'No', accuracy_score(y_test_A, y_pred_svm_A_chi),\n",
    "             precision_score(y_test_A, y_pred_svm_A_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_chi, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch A (Chi-square, Tuned) Best Params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.6603637239551969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68      4154\n",
      "           1       0.68      0.62      0.64      4149\n",
      "\n",
      "    accuracy                           0.66      8303\n",
      "   macro avg       0.66      0.66      0.66      8303\n",
      "weighted avg       0.66      0.66      0.66      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "svm_A_chi_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_A_chi_tuned.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_svm_A_chi_tuned = svm_A_chi_tuned.predict(X_test_A_chi)\n",
    "print(\"SVM Branch A (Chi-square, Tuned) Best Params:\", svm_A_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_chi_tuned))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_chi_tuned))\n",
    "store_result('A','SVM', 'Chi-square', 'Yes', accuracy_score(y_test_A, y_pred_svm_A_chi_tuned),\n",
    "             precision_score(y_test_A, y_pred_svm_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_chi_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch A (Correlation, Not Tuned) Accuracy: 0.6584367096230278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68      4154\n",
      "           1       0.68      0.59      0.63      4149\n",
      "\n",
      "    accuracy                           0.66      8303\n",
      "   macro avg       0.66      0.66      0.66      8303\n",
      "weighted avg       0.66      0.66      0.66      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM BRANCH A CORRELATION FEATURE SELECTION\n",
    "# NOT TUNED\n",
    "svm_A_corr = SVC(random_state=42)\n",
    "svm_A_corr.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_svm_A_corr = svm_A_corr.predict(X_test_A_corr)\n",
    "print(\"SVM Branch A (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_corr))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_corr))\n",
    "store_result('A','SVM', 'Correlation', 'No', accuracy_score(y_test_A, y_pred_svm_A_corr),\n",
    "             precision_score(y_test_A, y_pred_svm_A_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_corr, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch A (Correlation, Tuned) Best Params: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.6662652053474648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69      4154\n",
      "           1       0.70      0.59      0.64      4149\n",
      "\n",
      "    accuracy                           0.67      8303\n",
      "   macro avg       0.67      0.67      0.66      8303\n",
      "weighted avg       0.67      0.67      0.66      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "svm_A_corr_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_A_corr_tuned.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_svm_A_corr_tuned = svm_A_corr_tuned.predict(X_test_A_corr)\n",
    "print(\"SVM Branch A (Correlation, Tuned) Best Params:\", svm_A_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_svm_A_corr_tuned))\n",
    "print(classification_report(y_test_A, y_pred_svm_A_corr_tuned))\n",
    "store_result('A','SVM', 'Correlation', 'Yes', accuracy_score(y_test_A, y_pred_svm_A_corr_tuned),\n",
    "             precision_score(y_test_A, y_pred_svm_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_svm_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_svm_A_corr_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM BRANCH B (20/80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch B (No Feature Selection, Not Tuned) Accuracy: 0.6832470191497049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70     16576\n",
      "           1       0.71      0.61      0.66     16636\n",
      "\n",
      "    accuracy                           0.68     33212\n",
      "   macro avg       0.69      0.68      0.68     33212\n",
      "weighted avg       0.69      0.68      0.68     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NO FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "svm_B = SVC(random_state=42)\n",
    "svm_B.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_svm_B = svm_B.predict(X_test_B_scaled)\n",
    "print(\"SVM Branch B (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B))\n",
    "print(classification_report(y_test_B, y_pred_svm_B))\n",
    "store_result('B','SVM', 'None', 'No', accuracy_score(y_test_B, y_pred_svm_B),\n",
    "             precision_score(y_test_B, y_pred_svm_B, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch B (No Feature Selection, Tuned) Best Params: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.6840900879200289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.70     16576\n",
      "           1       0.72      0.61      0.66     16636\n",
      "\n",
      "    accuracy                           0.68     33212\n",
      "   macro avg       0.69      0.68      0.68     33212\n",
      "weighted avg       0.69      0.68      0.68     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "svm_B_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_B_tuned.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_svm_B_tuned = svm_B_tuned.predict(X_test_B_scaled)\n",
    "print(\"SVM Branch B (No Feature Selection, Tuned) Best Params:\", svm_B_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_tuned))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_tuned))\n",
    "store_result('B','SVM', 'None', 'Yes', accuracy_score(y_test_B, y_pred_svm_B_tuned),\n",
    "             precision_score(y_test_B, y_pred_svm_B_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch B (Chi-square, Not Tuned) Accuracy: 0.6600927375647356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68     16576\n",
      "           1       0.68      0.60      0.64     16636\n",
      "\n",
      "    accuracy                           0.66     33212\n",
      "   macro avg       0.66      0.66      0.66     33212\n",
      "weighted avg       0.66      0.66      0.66     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CHI SQUARE FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "\n",
    "svm_B_chi = SVC(random_state=42)\n",
    "svm_B_chi.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_svm_B_chi = svm_B_chi.predict(X_test_B_chi)\n",
    "print(\"SVM Branch B (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_chi))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_chi))\n",
    "store_result('B','SVM', 'Chi-square', 'No', accuracy_score(y_test_B, y_pred_svm_B_chi),\n",
    "             precision_score(y_test_B, y_pred_svm_B_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_chi, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch B (Chi-square, Tuned) Best Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.6600927375647356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68     16576\n",
      "           1       0.68      0.60      0.64     16636\n",
      "\n",
      "    accuracy                           0.66     33212\n",
      "   macro avg       0.66      0.66      0.66     33212\n",
      "weighted avg       0.66      0.66      0.66     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "svm_B_chi_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_B_chi_tuned.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_svm_B_chi_tuned = svm_B_chi_tuned.predict(X_test_B_chi)\n",
    "print(\"SVM Branch B (Chi-square, Tuned) Best Params:\", svm_B_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_chi_tuned))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_chi_tuned))\n",
    "store_result('B','SVM', 'Chi-square', 'Yes', accuracy_score(y_test_B, y_pred_svm_B_chi_tuned),\n",
    "             precision_score(y_test_B, y_pred_svm_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_chi_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch B (Correlation, Not Tuned) Accuracy: 0.6483499939780802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67     16576\n",
      "           1       0.67      0.59      0.63     16636\n",
      "\n",
      "    accuracy                           0.65     33212\n",
      "   macro avg       0.65      0.65      0.65     33212\n",
      "weighted avg       0.65      0.65      0.65     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CORRELATION FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "svm_B_corr = SVC(random_state=42)\n",
    "svm_B_corr.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_svm_B_corr = svm_B_corr.predict(X_test_B_corr)\n",
    "print(\"SVM Branch B (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_corr))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_corr))\n",
    "store_result('B','SVM', 'Correlation', 'No', accuracy_score(y_test_B, y_pred_svm_B_corr),\n",
    "             precision_score(y_test_B, y_pred_svm_B_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_corr, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Branch B (Correlation, Tuned) Best Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.6483499939780802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67     16576\n",
      "           1       0.67      0.59      0.63     16636\n",
      "\n",
      "    accuracy                           0.65     33212\n",
      "   macro avg       0.65      0.65      0.65     33212\n",
      "weighted avg       0.65      0.65      0.65     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "svm_B_corr_tuned = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "svm_B_corr_tuned.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_svm_B_corr_tuned = svm_B_corr_tuned.predict(X_test_B_corr)\n",
    "print(\"SVM Branch B (Correlation, Tuned) Best Params:\", svm_B_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_svm_B_corr_tuned))\n",
    "print(classification_report(y_test_B, y_pred_svm_B_corr_tuned))\n",
    "store_result('B','SVM', 'Correlation', 'Yes', accuracy_score(y_test_B, y_pred_svm_B_corr_tuned),\n",
    "             precision_score(y_test_B, y_pred_svm_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_svm_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_svm_B_corr_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE BRANCH A (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Branch A (No Feature Selection, Not Tuned) Accuracy: 0.6660243285559436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.66      4154\n",
      "           1       0.66      0.69      0.67      4149\n",
      "\n",
      "    accuracy                           0.67      8303\n",
      "   macro avg       0.67      0.67      0.67      8303\n",
      "weighted avg       0.67      0.67      0.67      8303\n",
      "\n",
      "Decision Tree Branch A (No Feature Selection, Tuned) Best Params: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Accuracy: 0.6687944116584367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68      4154\n",
      "           1       0.68      0.63      0.65      4149\n",
      "\n",
      "    accuracy                           0.67      8303\n",
      "   macro avg       0.67      0.67      0.67      8303\n",
      "weighted avg       0.67      0.67      0.67      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NO FEATURE SELECTION\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# NOT TUNED\n",
    "dt_A = DecisionTreeClassifier(random_state=42)\n",
    "dt_A.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_dt_A = dt_A.predict(X_test_A_scaled)\n",
    "print(\"Decision Tree Branch A (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A))\n",
    "print(classification_report(y_test_A, y_pred_dt_A))\n",
    "store_result('A','Decision Tree', 'None', 'No', accuracy_score(y_test_A, y_pred_dt_A),\n",
    "             precision_score(y_test_A, y_pred_dt_A, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "param_grid_dt = {'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5, 10]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dt_A_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_A_tuned.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_dt_A_tuned = dt_A_tuned.predict(X_test_A_scaled)\n",
    "print(\"Decision Tree Branch A (No Feature Selection, Tuned) Best Params:\", dt_A_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_tuned))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_tuned))\n",
    "store_result('A','Decision Tree', 'None', 'Yes', accuracy_score(y_test_A, y_pred_dt_A_tuned),\n",
    "             precision_score(y_test_A, y_pred_dt_A_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Branch A (Chi-square, Not Tuned) Accuracy: 0.6083343369866313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.68      0.63      4154\n",
      "           1       0.63      0.54      0.58      4149\n",
      "\n",
      "    accuracy                           0.61      8303\n",
      "   macro avg       0.61      0.61      0.61      8303\n",
      "weighted avg       0.61      0.61      0.61      8303\n",
      "\n",
      "Decision Tree Branch A (Chi-square, Tuned) Best Params: {'max_depth': 10, 'min_samples_split': 5}\n",
      "Accuracy: 0.6445862941105625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      4154\n",
      "           1       0.65      0.63      0.64      4149\n",
      "\n",
      "    accuracy                           0.64      8303\n",
      "   macro avg       0.64      0.64      0.64      8303\n",
      "weighted avg       0.64      0.64      0.64      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CHI SQUARE FEATURE SELECTION\n",
    "\n",
    "#NOT TUNED\n",
    "dt_A_chi = DecisionTreeClassifier(random_state=42)\n",
    "dt_A_chi.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_dt_A_chi = dt_A_chi.predict(X_test_A_chi)\n",
    "print(\"Decision Tree Branch A (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_chi))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_chi))\n",
    "store_result('A','Decision Tree', 'Chi-square', 'No', accuracy_score(y_test_A, y_pred_dt_A_chi),\n",
    "             precision_score(y_test_A, y_pred_dt_A_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_chi, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "dt_A_chi_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_A_chi_tuned.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_dt_A_chi_tuned = dt_A_chi_tuned.predict(X_test_A_chi)\n",
    "print(\"Decision Tree Branch A (Chi-square, Tuned) Best Params:\", dt_A_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_chi_tuned))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_chi_tuned))\n",
    "store_result('A','Decision Tree', 'Chi-square', 'Yes', accuracy_score(y_test_A, y_pred_dt_A_chi_tuned),\n",
    "             precision_score(y_test_A, y_pred_dt_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_chi_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Branch A (Correlation, Not Tuned) Accuracy: 0.64193664940383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      4154\n",
      "           1       0.64      0.65      0.64      4149\n",
      "\n",
      "    accuracy                           0.64      8303\n",
      "   macro avg       0.64      0.64      0.64      8303\n",
      "weighted avg       0.64      0.64      0.64      8303\n",
      "\n",
      "Decision Tree Branch A (Correlation, Tuned) Best Params: {'max_depth': 10, 'min_samples_split': 2}\n",
      "Accuracy: 0.646392870046971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      4154\n",
      "           1       0.65      0.63      0.64      4149\n",
      "\n",
      "    accuracy                           0.65      8303\n",
      "   macro avg       0.65      0.65      0.65      8303\n",
      "weighted avg       0.65      0.65      0.65      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CORRELATION FEATURE SELECTION\n",
    "# Not Tuned\n",
    "dt_A_corr = DecisionTreeClassifier(random_state=42)\n",
    "dt_A_corr.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_dt_A_corr = dt_A_corr.predict(X_test_A_corr)\n",
    "print(\"Decision Tree Branch A (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_corr))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_corr))\n",
    "store_result('A','Decision Tree', 'Correlation', 'No', accuracy_score(y_test_A, y_pred_dt_A_corr),\n",
    "             precision_score(y_test_A, y_pred_dt_A_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_corr, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "dt_A_corr_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_A_corr_tuned.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_dt_A_corr_tuned = dt_A_corr_tuned.predict(X_test_A_corr)\n",
    "print(\"Decision Tree Branch A (Correlation, Tuned) Best Params:\", dt_A_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_dt_A_corr_tuned))\n",
    "print(classification_report(y_test_A, y_pred_dt_A_corr_tuned))\n",
    "store_result('A','Decision Tree', 'Correlation', 'Yes', accuracy_score(y_test_A, y_pred_dt_A_corr_tuned),\n",
    "             precision_score(y_test_A, y_pred_dt_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_dt_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_dt_A_corr_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE BRANCH B (20/80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Branch B (No Feature Selection, Not Tuned) Accuracy: 0.6155004215343851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61     16576\n",
      "           1       0.62      0.62      0.62     16636\n",
      "\n",
      "    accuracy                           0.62     33212\n",
      "   macro avg       0.62      0.62      0.62     33212\n",
      "weighted avg       0.62      0.62      0.62     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NO FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "\n",
    "dt_B = DecisionTreeClassifier(random_state=42)\n",
    "dt_B.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_dt_B = dt_B.predict(X_test_B_scaled)\n",
    "print(\"Decision Tree Branch B (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B))\n",
    "print(classification_report(y_test_B, y_pred_dt_B))\n",
    "store_result('B','Decision Tree', 'None', 'No', accuracy_score(y_test_B, y_pred_dt_B),\n",
    "             precision_score(y_test_B, y_pred_dt_B, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Branch B (No Feature Selection, Tuned) Best Params: {'max_depth': 5, 'min_samples_split': 2}\n",
      "Accuracy: 0.6595808743827533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70     16576\n",
      "           1       0.73      0.51      0.60     16636\n",
      "\n",
      "    accuracy                           0.66     33212\n",
      "   macro avg       0.68      0.66      0.65     33212\n",
      "weighted avg       0.68      0.66      0.65     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "dt_B_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_B_tuned.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_dt_B_tuned = dt_B_tuned.predict(X_test_B_scaled)\n",
    "print(\"Decision Tree Branch B (No Feature Selection, Tuned) Best Params:\", dt_B_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_tuned))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_tuned))\n",
    "store_result('B','Decision Tree', 'None', 'Yes', accuracy_score(y_test_B, y_pred_dt_B_tuned),\n",
    "             precision_score(y_test_B, y_pred_dt_B_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Branch B (Chi-square, Not Tuned) Accuracy: 0.5918342767674335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61     16576\n",
      "           1       0.60      0.56      0.58     16636\n",
      "\n",
      "    accuracy                           0.59     33212\n",
      "   macro avg       0.59      0.59      0.59     33212\n",
      "weighted avg       0.59      0.59      0.59     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CHI SQUARE FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "dt_B_chi = DecisionTreeClassifier(random_state=42)\n",
    "dt_B_chi.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_dt_B_chi = dt_B_chi.predict(X_test_B_chi)\n",
    "print(\"Decision Tree Branch B (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_chi))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_chi))\n",
    "store_result('B','Decision Tree', 'Chi-square', 'No', accuracy_score(y_test_B, y_pred_dt_B_chi),\n",
    "             precision_score(y_test_B, y_pred_dt_B_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_chi, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Branch B (Chi-square, Tuned) Best Params: {'max_depth': 5, 'min_samples_split': 10}\n",
      "Accuracy: 0.636637359990365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68     16576\n",
      "           1       0.68      0.51      0.59     16636\n",
      "\n",
      "    accuracy                           0.64     33212\n",
      "   macro avg       0.65      0.64      0.63     33212\n",
      "weighted avg       0.65      0.64      0.63     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "dt_B_chi_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_B_chi_tuned.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_dt_B_chi_tuned = dt_B_chi_tuned.predict(X_test_B_chi)\n",
    "print(\"Decision Tree Branch B (Chi-square, Tuned) Best Params:\", dt_B_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_chi_tuned))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_chi_tuned))\n",
    "store_result('B','Decision Tree', 'Chi-square', 'Yes', accuracy_score(y_test_B, y_pred_dt_B_chi_tuned),\n",
    "             precision_score(y_test_B, y_pred_dt_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_chi_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Branch B (Correlation, Not Tuned) Accuracy: 0.5919848247621342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59     16576\n",
      "           1       0.59      0.60      0.60     16636\n",
      "\n",
      "    accuracy                           0.59     33212\n",
      "   macro avg       0.59      0.59      0.59     33212\n",
      "weighted avg       0.59      0.59      0.59     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CORRELATION FEATURE SELECTION\n",
    "#NOT TUNED\n",
    "dt_B_corr = DecisionTreeClassifier(random_state=42)\n",
    "dt_B_corr.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_dt_B_corr = dt_B_corr.predict(X_test_B_corr)\n",
    "print(\"Decision Tree Branch B (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_corr))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_corr))\n",
    "store_result('B','Decision Tree', 'Correlation', 'No', accuracy_score(y_test_B, y_pred_dt_B_corr),\n",
    "             precision_score(y_test_B, y_pred_dt_B_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_corr, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Branch B (Correlation, Tuned) Best Params: {'max_depth': 5, 'min_samples_split': 10}\n",
      "Accuracy: 0.6357942912200409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65     16576\n",
      "           1       0.65      0.58      0.62     16636\n",
      "\n",
      "    accuracy                           0.64     33212\n",
      "   macro avg       0.64      0.64      0.63     33212\n",
      "weighted avg       0.64      0.64      0.63     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "dt_B_corr_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='accuracy')\n",
    "dt_B_corr_tuned.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_dt_B_corr_tuned = dt_B_corr_tuned.predict(X_test_B_corr)\n",
    "print(\"Decision Tree Branch B (Correlation, Tuned) Best Params:\", dt_B_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_dt_B_corr_tuned))\n",
    "print(classification_report(y_test_B, y_pred_dt_B_corr_tuned))\n",
    "store_result('B','Decision Tree', 'Correlation', 'Yes', accuracy_score(y_test_B, y_pred_dt_B_corr_tuned),\n",
    "             precision_score(y_test_B, y_pred_dt_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_dt_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_dt_B_corr_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST BRANCH A (80/20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch A (No Feature Selection, Not Tuned) Accuracy: 0.7263639648319884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73      4154\n",
      "           1       0.74      0.70      0.72      4149\n",
      "\n",
      "    accuracy                           0.73      8303\n",
      "   macro avg       0.73      0.73      0.73      8303\n",
      "weighted avg       0.73      0.73      0.73      8303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:44:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch A (No Feature Selection, Tuned) Best Params: {'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 200}\n",
      "Accuracy: 0.7600867156449476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      4154\n",
      "           1       0.76      0.76      0.76      4149\n",
      "\n",
      "    accuracy                           0.76      8303\n",
      "   macro avg       0.76      0.76      0.76      8303\n",
      "weighted avg       0.76      0.76      0.76      8303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NO FEATURE SELECTION\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Not Tuned\n",
    "xgb_A = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_A.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_xgb_A = xgb_A.predict(X_test_A_scaled)\n",
    "print(\"XGBoost Branch A (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A))\n",
    "store_result('A','XGBoost', 'None', 'No', accuracy_score(y_test_A, y_pred_xgb_A),\n",
    "             precision_score(y_test_A, y_pred_xgb_A, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "param_grid_xgb = {'max_depth': [3, 5, 10], 'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [100, 200]}\n",
    "xgb_A_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_A_tuned.fit(X_train_A_scaled, y_train_A)\n",
    "y_pred_xgb_A_tuned = xgb_A_tuned.predict(X_test_A_scaled)\n",
    "print(\"XGBoost Branch A (No Feature Selection, Tuned) Best Params:\", xgb_A_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_tuned))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_tuned))\n",
    "store_result('A','XGBoost', 'None', 'Yes', accuracy_score(y_test_A, y_pred_xgb_A_tuned),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch A (Chi-square, Not Tuned) Accuracy: 0.6620498614958449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67      4154\n",
      "           1       0.67      0.64      0.65      4149\n",
      "\n",
      "    accuracy                           0.66      8303\n",
      "   macro avg       0.66      0.66      0.66      8303\n",
      "weighted avg       0.66      0.66      0.66      8303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch A (Chi-square, Tuned) Best Params: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
      "Accuracy: 0.6690352884499579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67      4154\n",
      "           1       0.67      0.66      0.66      4149\n",
      "\n",
      "    accuracy                           0.67      8303\n",
      "   macro avg       0.67      0.67      0.67      8303\n",
      "weighted avg       0.67      0.67      0.67      8303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:45:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# CHI SQUARE FEATURE SELECTION\n",
    "\n",
    "# Not Tuned\n",
    "xgb_A_chi = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_A_chi.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_xgb_A_chi = xgb_A_chi.predict(X_test_A_chi)\n",
    "print(\"XGBoost Branch A (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_chi))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_chi))\n",
    "store_result('A','XGBoost', 'Chi-square', 'No', accuracy_score(y_test_A, y_pred_xgb_A_chi),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_chi, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "xgb_A_chi_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_A_chi_tuned.fit(X_train_A_chi, y_train_A)\n",
    "y_pred_xgb_A_chi_tuned = xgb_A_chi_tuned.predict(X_test_A_chi)\n",
    "print(\"XGBoost Branch A (Chi-square, Tuned) Best Params:\", xgb_A_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_chi_tuned))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_chi_tuned))\n",
    "store_result('A','XGBoost', 'Chi-square', 'Yes', accuracy_score(y_test_A, y_pred_xgb_A_chi_tuned),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_chi_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch A (Correlation, Not Tuned) Accuracy: 0.6774659761531976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.69      4154\n",
      "           1       0.69      0.64      0.66      4149\n",
      "\n",
      "    accuracy                           0.68      8303\n",
      "   macro avg       0.68      0.68      0.68      8303\n",
      "weighted avg       0.68      0.68      0.68      8303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch A (Correlation, Tuned) Best Params: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}\n",
      "Accuracy: 0.6767433457786343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69      4154\n",
      "           1       0.69      0.63      0.66      4149\n",
      "\n",
      "    accuracy                           0.68      8303\n",
      "   macro avg       0.68      0.68      0.68      8303\n",
      "weighted avg       0.68      0.68      0.68      8303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "#CORRELATION FEATURE SELECTION\n",
    "# Not Tuned\n",
    "xgb_A_corr = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_A_corr.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_xgb_A_corr = xgb_A_corr.predict(X_test_A_corr)\n",
    "print(\"XGBoost Branch A (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_corr))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_corr))\n",
    "store_result('A','XGBoost', 'Correlation', 'No', accuracy_score(y_test_A, y_pred_xgb_A_corr),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_corr, average='weighted', zero_division=0))\n",
    "\n",
    "# Tuned\n",
    "xgb_A_corr_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_A_corr_tuned.fit(X_train_A_corr, y_train_A)\n",
    "y_pred_xgb_A_corr_tuned = xgb_A_corr_tuned.predict(X_test_A_corr)\n",
    "print(\"XGBoost Branch A (Correlation, Tuned) Best Params:\", xgb_A_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_A, y_pred_xgb_A_corr_tuned))\n",
    "print(classification_report(y_test_A, y_pred_xgb_A_corr_tuned))\n",
    "store_result('A','XGBoost', 'Correlation', 'Yes', accuracy_score(y_test_A, y_pred_xgb_A_corr_tuned),\n",
    "             precision_score(y_test_A, y_pred_xgb_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_A, y_pred_xgb_A_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_A, y_pred_xgb_A_corr_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST BRANCH B (20/80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch B (No Feature Selection, Not Tuned) Accuracy: 0.6951704203300012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70     16576\n",
      "           1       0.70      0.68      0.69     16636\n",
      "\n",
      "    accuracy                           0.70     33212\n",
      "   macro avg       0.70      0.70      0.70     33212\n",
      "weighted avg       0.70      0.70      0.70     33212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "#FEATURE SELECTION\n",
    "#NOT TUNED \n",
    "xgb_B = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_B.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_xgb_B = xgb_B.predict(X_test_B_scaled)\n",
    "print(\"XGBoost Branch B (No Feature Selection, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B))\n",
    "store_result('B','XGBoost', 'None', 'No', accuracy_score(y_test_B, y_pred_xgb_B),\n",
    "             precision_score(y_test_B, y_pred_xgb_B, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch B (No Feature Selection, Tuned) Best Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Accuracy: 0.7019751896904733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71     16576\n",
      "           1       0.72      0.66      0.69     16636\n",
      "\n",
      "    accuracy                           0.70     33212\n",
      "   macro avg       0.70      0.70      0.70     33212\n",
      "weighted avg       0.70      0.70      0.70     33212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "xgb_B_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_B_tuned.fit(X_train_B_scaled, y_train_B)\n",
    "y_pred_xgb_B_tuned = xgb_B_tuned.predict(X_test_B_scaled)\n",
    "print(\"XGBoost Branch B (No Feature Selection, Tuned) Best Params:\", xgb_B_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_tuned))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_tuned))\n",
    "store_result('B','XGBoost', 'None', 'Yes', accuracy_score(y_test_B, y_pred_xgb_B_tuned),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch B (Chi-square, Not Tuned) Accuracy: 0.6482596651812598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.66     16576\n",
      "           1       0.66      0.63      0.64     16636\n",
      "\n",
      "    accuracy                           0.65     33212\n",
      "   macro avg       0.65      0.65      0.65     33212\n",
      "weighted avg       0.65      0.65      0.65     33212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# CHI SQUARE FEATURE SELECTION\n",
    "# NOT TUNED\n",
    "\n",
    "xgb_B_chi = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_B_chi.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_xgb_B_chi = xgb_B_chi.predict(X_test_B_chi)\n",
    "print(\"XGBoost Branch B (Chi-square, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_chi))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_chi))\n",
    "store_result('B','XGBoost', 'Chi-square', 'No', accuracy_score(y_test_B, y_pred_xgb_B_chi),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_chi, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_chi, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_chi, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch B (Chi-square, Tuned) Best Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Accuracy: 0.676713236179694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.69     16576\n",
      "           1       0.69      0.64      0.67     16636\n",
      "\n",
      "    accuracy                           0.68     33212\n",
      "   macro avg       0.68      0.68      0.68     33212\n",
      "weighted avg       0.68      0.68      0.68     33212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "#TUNED\n",
    "xgb_B_chi_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_B_chi_tuned.fit(X_train_B_chi, y_train_B)\n",
    "y_pred_xgb_B_chi_tuned = xgb_B_chi_tuned.predict(X_test_B_chi)\n",
    "print(\"XGBoost Branch B (Chi-square, Tuned) Best Params:\", xgb_B_chi_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_chi_tuned))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_chi_tuned))\n",
    "store_result('B','XGBoost', 'Chi-square', 'Yes', accuracy_score(y_test_B, y_pred_xgb_B_chi_tuned),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_chi_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_chi_tuned, average='weighted', zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch B (Correlation, Not Tuned) Accuracy: 0.6497049259303866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65     16576\n",
      "           1       0.65      0.64      0.65     16636\n",
      "\n",
      "    accuracy                           0.65     33212\n",
      "   macro avg       0.65      0.65      0.65     33212\n",
      "weighted avg       0.65      0.65      0.65     33212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# CORRELATION FEATURE SELECTION\n",
    "# NOT TUNED\n",
    "xgb_B_corr = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_B_corr.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_xgb_B_corr = xgb_B_corr.predict(X_test_B_corr)\n",
    "print(\"XGBoost Branch B (Correlation, Not Tuned) Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_corr))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_corr))\n",
    "store_result('B','XGBoost', 'Correlation', 'No', accuracy_score(y_test_B, y_pred_xgb_B_corr),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_corr, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_corr, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_corr, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Branch B (Correlation, Tuned) Best Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Accuracy: 0.6583764904251476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67     16576\n",
      "           1       0.67      0.63      0.65     16636\n",
      "\n",
      "    accuracy                           0.66     33212\n",
      "   macro avg       0.66      0.66      0.66     33212\n",
      "weighted avg       0.66      0.66      0.66     33212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# TUNED\n",
    "xgb_B_corr_tuned = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=3, scoring='accuracy')\n",
    "xgb_B_corr_tuned.fit(X_train_B_corr, y_train_B)\n",
    "y_pred_xgb_B_corr_tuned = xgb_B_corr_tuned.predict(X_test_B_corr)\n",
    "print(\"XGBoost Branch B (Correlation, Tuned) Best Params:\", xgb_B_corr_tuned.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_B, y_pred_xgb_B_corr_tuned))\n",
    "print(classification_report(y_test_B, y_pred_xgb_B_corr_tuned))\n",
    "store_result('B','XGBoost', 'Correlation', 'Yes', accuracy_score(y_test_B, y_pred_xgb_B_corr_tuned),\n",
    "             precision_score(y_test_B, y_pred_xgb_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             recall_score(y_test_B, y_pred_xgb_B_corr_tuned, average='weighted', zero_division=0),\n",
    "             f1_score(y_test_B, y_pred_xgb_B_corr_tuned, average='weighted', zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION COMPARISON TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Branch</th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature Selection</th>\n",
       "      <th>Tuned</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>No</td>\n",
       "      <td>0.608334</td>\n",
       "      <td>0.610549</td>\n",
       "      <td>0.608334</td>\n",
       "      <td>0.606316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.644586</td>\n",
       "      <td>0.644711</td>\n",
       "      <td>0.644586</td>\n",
       "      <td>0.644502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.641937</td>\n",
       "      <td>0.641954</td>\n",
       "      <td>0.641937</td>\n",
       "      <td>0.641928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.641937</td>\n",
       "      <td>0.641954</td>\n",
       "      <td>0.641937</td>\n",
       "      <td>0.641928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.646393</td>\n",
       "      <td>0.646483</td>\n",
       "      <td>0.646393</td>\n",
       "      <td>0.646333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>0.666024</td>\n",
       "      <td>0.666371</td>\n",
       "      <td>0.666024</td>\n",
       "      <td>0.665859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.668794</td>\n",
       "      <td>0.669905</td>\n",
       "      <td>0.668794</td>\n",
       "      <td>0.668236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>No</td>\n",
       "      <td>0.658316</td>\n",
       "      <td>0.659172</td>\n",
       "      <td>0.658316</td>\n",
       "      <td>0.657841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.660364</td>\n",
       "      <td>0.661629</td>\n",
       "      <td>0.660364</td>\n",
       "      <td>0.659679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.658437</td>\n",
       "      <td>0.661453</td>\n",
       "      <td>0.658437</td>\n",
       "      <td>0.656805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.666265</td>\n",
       "      <td>0.670347</td>\n",
       "      <td>0.666265</td>\n",
       "      <td>0.664223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>0.693725</td>\n",
       "      <td>0.697679</td>\n",
       "      <td>0.693725</td>\n",
       "      <td>0.692163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.693725</td>\n",
       "      <td>0.697679</td>\n",
       "      <td>0.693725</td>\n",
       "      <td>0.692163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>No</td>\n",
       "      <td>0.662050</td>\n",
       "      <td>0.662440</td>\n",
       "      <td>0.662050</td>\n",
       "      <td>0.661837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>No</td>\n",
       "      <td>0.662050</td>\n",
       "      <td>0.662440</td>\n",
       "      <td>0.662050</td>\n",
       "      <td>0.661837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>No</td>\n",
       "      <td>0.662050</td>\n",
       "      <td>0.662440</td>\n",
       "      <td>0.662050</td>\n",
       "      <td>0.661837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.669035</td>\n",
       "      <td>0.669125</td>\n",
       "      <td>0.669035</td>\n",
       "      <td>0.668987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.677466</td>\n",
       "      <td>0.678485</td>\n",
       "      <td>0.677466</td>\n",
       "      <td>0.676991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.677466</td>\n",
       "      <td>0.678485</td>\n",
       "      <td>0.677466</td>\n",
       "      <td>0.676991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.677466</td>\n",
       "      <td>0.678485</td>\n",
       "      <td>0.677466</td>\n",
       "      <td>0.676991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.677466</td>\n",
       "      <td>0.678485</td>\n",
       "      <td>0.677466</td>\n",
       "      <td>0.676991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.676743</td>\n",
       "      <td>0.678051</td>\n",
       "      <td>0.676743</td>\n",
       "      <td>0.676133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>0.726364</td>\n",
       "      <td>0.727004</td>\n",
       "      <td>0.726364</td>\n",
       "      <td>0.726164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.760087</td>\n",
       "      <td>0.760101</td>\n",
       "      <td>0.760087</td>\n",
       "      <td>0.760083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>No</td>\n",
       "      <td>0.591834</td>\n",
       "      <td>0.592356</td>\n",
       "      <td>0.591834</td>\n",
       "      <td>0.591341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>B</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.636637</td>\n",
       "      <td>0.646038</td>\n",
       "      <td>0.636637</td>\n",
       "      <td>0.630881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.591985</td>\n",
       "      <td>0.591989</td>\n",
       "      <td>0.591985</td>\n",
       "      <td>0.591966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.635794</td>\n",
       "      <td>0.637367</td>\n",
       "      <td>0.635794</td>\n",
       "      <td>0.634829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>0.615503</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>0.615491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.659581</td>\n",
       "      <td>0.676665</td>\n",
       "      <td>0.659581</td>\n",
       "      <td>0.651336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>No</td>\n",
       "      <td>0.660093</td>\n",
       "      <td>0.662754</td>\n",
       "      <td>0.660093</td>\n",
       "      <td>0.658777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.660093</td>\n",
       "      <td>0.662754</td>\n",
       "      <td>0.660093</td>\n",
       "      <td>0.658777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.648350</td>\n",
       "      <td>0.650736</td>\n",
       "      <td>0.648350</td>\n",
       "      <td>0.647038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.648350</td>\n",
       "      <td>0.650736</td>\n",
       "      <td>0.648350</td>\n",
       "      <td>0.647038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>0.683247</td>\n",
       "      <td>0.686878</td>\n",
       "      <td>0.683247</td>\n",
       "      <td>0.681774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.684090</td>\n",
       "      <td>0.688079</td>\n",
       "      <td>0.684090</td>\n",
       "      <td>0.682482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>B</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>No</td>\n",
       "      <td>0.648260</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>0.648260</td>\n",
       "      <td>0.648097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>B</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Chi-square</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.676713</td>\n",
       "      <td>0.677681</td>\n",
       "      <td>0.676713</td>\n",
       "      <td>0.676313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>B</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>No</td>\n",
       "      <td>0.649705</td>\n",
       "      <td>0.649852</td>\n",
       "      <td>0.649705</td>\n",
       "      <td>0.649639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>B</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.658376</td>\n",
       "      <td>0.659097</td>\n",
       "      <td>0.658376</td>\n",
       "      <td>0.658031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>B</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>0.695170</td>\n",
       "      <td>0.695301</td>\n",
       "      <td>0.695170</td>\n",
       "      <td>0.695132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>B</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.701975</td>\n",
       "      <td>0.703239</td>\n",
       "      <td>0.701975</td>\n",
       "      <td>0.701547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Branch          Model Feature Selection Tuned  Accuracy  Precision  \\\n",
       "14      A  Decision Tree        Chi-square    No  0.608334   0.610549   \n",
       "15      A  Decision Tree        Chi-square   Yes  0.644586   0.644711   \n",
       "16      A  Decision Tree       Correlation    No  0.641937   0.641954   \n",
       "17      A  Decision Tree       Correlation    No  0.641937   0.641954   \n",
       "18      A  Decision Tree       Correlation   Yes  0.646393   0.646483   \n",
       "12      A  Decision Tree              None    No  0.666024   0.666371   \n",
       "13      A  Decision Tree              None   Yes  0.668794   0.669905   \n",
       "2       A            SVM        Chi-square    No  0.658316   0.659172   \n",
       "3       A            SVM        Chi-square   Yes  0.660364   0.661629   \n",
       "4       A            SVM       Correlation    No  0.658437   0.661453   \n",
       "5       A            SVM       Correlation   Yes  0.666265   0.670347   \n",
       "0       A            SVM              None    No  0.693725   0.697679   \n",
       "1       A            SVM              None   Yes  0.693725   0.697679   \n",
       "27      A        XGBoost        Chi-square    No  0.662050   0.662440   \n",
       "28      A        XGBoost        Chi-square    No  0.662050   0.662440   \n",
       "29      A        XGBoost        Chi-square    No  0.662050   0.662440   \n",
       "30      A        XGBoost        Chi-square   Yes  0.669035   0.669125   \n",
       "31      A        XGBoost       Correlation    No  0.677466   0.678485   \n",
       "32      A        XGBoost       Correlation    No  0.677466   0.678485   \n",
       "33      A        XGBoost       Correlation    No  0.677466   0.678485   \n",
       "34      A        XGBoost       Correlation    No  0.677466   0.678485   \n",
       "35      A        XGBoost       Correlation   Yes  0.676743   0.678051   \n",
       "25      A        XGBoost              None    No  0.726364   0.727004   \n",
       "26      A        XGBoost              None   Yes  0.760087   0.760101   \n",
       "21      B  Decision Tree        Chi-square    No  0.591834   0.592356   \n",
       "22      B  Decision Tree        Chi-square   Yes  0.636637   0.646038   \n",
       "23      B  Decision Tree       Correlation    No  0.591985   0.591989   \n",
       "24      B  Decision Tree       Correlation   Yes  0.635794   0.637367   \n",
       "19      B  Decision Tree              None    No  0.615500   0.615503   \n",
       "20      B  Decision Tree              None   Yes  0.659581   0.676665   \n",
       "8       B            SVM        Chi-square    No  0.660093   0.662754   \n",
       "9       B            SVM        Chi-square   Yes  0.660093   0.662754   \n",
       "10      B            SVM       Correlation    No  0.648350   0.650736   \n",
       "11      B            SVM       Correlation   Yes  0.648350   0.650736   \n",
       "6       B            SVM              None    No  0.683247   0.686878   \n",
       "7       B            SVM              None   Yes  0.684090   0.688079   \n",
       "38      B        XGBoost        Chi-square    No  0.648260   0.648586   \n",
       "39      B        XGBoost        Chi-square   Yes  0.676713   0.677681   \n",
       "40      B        XGBoost       Correlation    No  0.649705   0.649852   \n",
       "41      B        XGBoost       Correlation   Yes  0.658376   0.659097   \n",
       "36      B        XGBoost              None    No  0.695170   0.695301   \n",
       "37      B        XGBoost              None   Yes  0.701975   0.703239   \n",
       "\n",
       "      Recall  F1-score  \n",
       "14  0.608334  0.606316  \n",
       "15  0.644586  0.644502  \n",
       "16  0.641937  0.641928  \n",
       "17  0.641937  0.641928  \n",
       "18  0.646393  0.646333  \n",
       "12  0.666024  0.665859  \n",
       "13  0.668794  0.668236  \n",
       "2   0.658316  0.657841  \n",
       "3   0.660364  0.659679  \n",
       "4   0.658437  0.656805  \n",
       "5   0.666265  0.664223  \n",
       "0   0.693725  0.692163  \n",
       "1   0.693725  0.692163  \n",
       "27  0.662050  0.661837  \n",
       "28  0.662050  0.661837  \n",
       "29  0.662050  0.661837  \n",
       "30  0.669035  0.668987  \n",
       "31  0.677466  0.676991  \n",
       "32  0.677466  0.676991  \n",
       "33  0.677466  0.676991  \n",
       "34  0.677466  0.676991  \n",
       "35  0.676743  0.676133  \n",
       "25  0.726364  0.726164  \n",
       "26  0.760087  0.760083  \n",
       "21  0.591834  0.591341  \n",
       "22  0.636637  0.630881  \n",
       "23  0.591985  0.591966  \n",
       "24  0.635794  0.634829  \n",
       "19  0.615500  0.615491  \n",
       "20  0.659581  0.651336  \n",
       "8   0.660093  0.658777  \n",
       "9   0.660093  0.658777  \n",
       "10  0.648350  0.647038  \n",
       "11  0.648350  0.647038  \n",
       "6   0.683247  0.681774  \n",
       "7   0.684090  0.682482  \n",
       "38  0.648260  0.648097  \n",
       "39  0.676713  0.676313  \n",
       "40  0.649705  0.649639  \n",
       "41  0.658376  0.658031  \n",
       "36  0.695170  0.695132  \n",
       "37  0.701975  0.701547  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame from results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort for readability\n",
    "results_df = results_df.sort_values(by=['Branch', 'Model', 'Feature Selection', 'Tuned'])\n",
    "\n",
    "# Display the table\n",
    "display(results_df)\n",
    "\n",
    "# Optionally, highlight the best accuracy and F1-score in each branch/model\n",
    "def highlight_best(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: lightgreen' if v else '' for v in is_max]\n",
    "\n",
    "# Highlight best per Branch+Model group\n",
    "styled = results_df.style\n",
    "for (branch, model), group in results_df.groupby(['Branch', 'Model']):\n",
    "    idx = group['Accuracy'].idxmax()\n",
    "    styled = styled.apply(lambda x: ['background-color: lightgreen' if i == idx else '' for i in x.index], subset=['Accuracy'])\n",
    "    idx_f1 = group['F1-score'].idxmax()\n",
    "    styled = styled.apply(lambda x: ['background-color: lightblue' if i == idx_f1 else '' for i in x.index], subset=['F1-score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STORING ALL TRAINED MODELS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All models (tuned and not tuned), scalers, and selectors saved with clear labels!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# BRANCH A (80% train, 20% test)\n",
    "# =========================\n",
    "\n",
    "# --- No Feature Selection ---\n",
    "joblib.dump(svm_A, 'svm_A_model_not_tuned.pkl')         # SVM, Branch A, no feature selection, not tuned\n",
    "joblib.dump(svm_A_tuned, 'svm_A_model_tuned.pkl')       # SVM, Branch A, no feature selection, tuned\n",
    "joblib.dump(dt_A, 'dt_A_model_not_tuned.pkl')           # Decision Tree, Branch A, no feature selection, not tuned\n",
    "joblib.dump(dt_A_tuned, 'dt_A_model_tuned.pkl')         # Decision Tree, Branch A, no feature selection, tuned\n",
    "joblib.dump(xgb_A, 'xgb_A_model_not_tuned.pkl')         # XGBoost, Branch A, no feature selection, not tuned\n",
    "joblib.dump(xgb_A_tuned, 'xgb_A_model_tuned.pkl')       # XGBoost, Branch A, no feature selection, tuned\n",
    "joblib.dump(scaler_A, 'scaler_A.pkl')                  # StandardScaler for Branch A\n",
    "\n",
    "# --- Chi-square Feature Selection ---\n",
    "joblib.dump(svm_A_chi, 'svm_A_chi_model_not_tuned.pkl')         # SVM, Branch A, chi-square, not tuned\n",
    "joblib.dump(svm_A_chi_tuned, 'svm_A_chi_model_tuned.pkl')       # SVM, Branch A, chi-square, tuned\n",
    "joblib.dump(dt_A_chi, 'dt_A_chi_model_not_tuned.pkl')           # Decision Tree, Branch A, chi-square, not tuned\n",
    "joblib.dump(dt_A_chi_tuned, 'dt_A_chi_model_tuned.pkl')         # Decision Tree, Branch A, chi-square, tuned\n",
    "joblib.dump(xgb_A_chi, 'xgb_A_chi_model_not_tuned.pkl')         # XGBoost, Branch A, chi-square, not tuned\n",
    "joblib.dump(xgb_A_chi_tuned, 'xgb_A_chi_model_tuned.pkl')       # XGBoost, Branch A, chi-square, tuned\n",
    "joblib.dump(selector_A, 'selector_A.pkl')                       # Chi-square selector for Branch A\n",
    "joblib.dump(minmax_scaler_A, 'minmax_scaler_A.pkl')             # MinMaxScaler for chi-square, Branch A\n",
    "\n",
    "# --- Correlation Feature Selection ---\n",
    "joblib.dump(svm_A_corr, 'svm_A_corr_model_not_tuned.pkl')       # SVM, Branch A, correlation, not tuned\n",
    "joblib.dump(svm_A_corr_tuned, 'svm_A_corr_model_tuned.pkl')     # SVM, Branch A, correlation, tuned\n",
    "joblib.dump(dt_A_corr, 'dt_A_corr_model_not_tuned.pkl')         # Decision Tree, Branch A, correlation, not tuned\n",
    "joblib.dump(dt_A_corr_tuned, 'dt_A_corr_model_tuned.pkl')       # Decision Tree, Branch A, correlation, tuned\n",
    "joblib.dump(xgb_A_corr, 'xgb_A_corr_model_not_tuned.pkl')       # XGBoost, Branch A, correlation, not tuned\n",
    "joblib.dump(xgb_A_corr_tuned, 'xgb_A_corr_model_tuned.pkl')     # XGBoost, Branch A, correlation, tuned\n",
    "# Use scaler_A for correlation branch as well\n",
    "\n",
    "# =========================\n",
    "# BRANCH B (20% train, 80% test)\n",
    "# =========================\n",
    "\n",
    "# --- No Feature Selection ---\n",
    "joblib.dump(svm_B, 'svm_B_model_not_tuned.pkl')         # SVM, Branch B, no feature selection, not tuned\n",
    "joblib.dump(svm_B_tuned, 'svm_B_model_tuned.pkl')       # SVM, Branch B, no feature selection, tuned\n",
    "joblib.dump(dt_B, 'dt_B_model_not_tuned.pkl')           # Decision Tree, Branch B, no feature selection, not tuned\n",
    "joblib.dump(dt_B_tuned, 'dt_B_model_tuned.pkl')         # Decision Tree, Branch B, no feature selection, tuned\n",
    "joblib.dump(xgb_B, 'xgb_B_model_not_tuned.pkl')         # XGBoost, Branch B, no feature selection, not tuned\n",
    "joblib.dump(xgb_B_tuned, 'xgb_B_model_tuned.pkl')       # XGBoost, Branch B, no feature selection, tuned\n",
    "joblib.dump(scaler_B, 'scaler_B.pkl')                  # StandardScaler for Branch B\n",
    "\n",
    "# --- Chi-square Feature Selection ---\n",
    "joblib.dump(svm_B_chi, 'svm_B_chi_model_not_tuned.pkl')         # SVM, Branch B, chi-square, not tuned\n",
    "joblib.dump(svm_B_chi_tuned, 'svm_B_chi_model_tuned.pkl')       # SVM, Branch B, chi-square, tuned\n",
    "joblib.dump(dt_B_chi, 'dt_B_chi_model_not_tuned.pkl')           # Decision Tree, Branch B, chi-square, not tuned\n",
    "joblib.dump(dt_B_chi_tuned, 'dt_B_chi_model_tuned.pkl')         # Decision Tree, Branch B, chi-square, tuned\n",
    "joblib.dump(xgb_B_chi, 'xgb_B_chi_model_not_tuned.pkl')         # XGBoost, Branch B, chi-square, not tuned\n",
    "joblib.dump(xgb_B_chi_tuned, 'xgb_B_chi_model_tuned.pkl')       # XGBoost, Branch B, chi-square, tuned\n",
    "joblib.dump(selector_B, 'selector_B.pkl')                       # Chi-square selector for Branch B\n",
    "joblib.dump(minmax_scaler_B, 'minmax_scaler_B.pkl')             # MinMaxScaler for chi-square, Branch B\n",
    "\n",
    "# --- Correlation Feature Selection ---\n",
    "joblib.dump(svm_B_corr, 'svm_B_corr_model_not_tuned.pkl')       # SVM, Branch B, correlation, not tuned\n",
    "joblib.dump(svm_B_corr_tuned, 'svm_B_corr_model_tuned.pkl')     # SVM, Branch B, correlation, tuned\n",
    "joblib.dump(dt_B_corr, 'dt_B_corr_model_not_tuned.pkl')         # Decision Tree, Branch B, correlation, not tuned\n",
    "joblib.dump(dt_B_corr_tuned, 'dt_B_corr_model_tuned.pkl')       # Decision Tree, Branch B, correlation, tuned\n",
    "joblib.dump(xgb_B_corr, 'xgb_B_corr_model_not_tuned.pkl')       # XGBoost, Branch B, correlation, not tuned\n",
    "joblib.dump(xgb_B_corr_tuned, 'xgb_B_corr_model_tuned.pkl')     # XGBoost, Branch B, correlation, tuned\n",
    "# Use scaler_B for correlation branch as well\n",
    "\n",
    "print(\"✅ All models (tuned and not tuned), scalers, and selectors saved with clear labels!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATIONS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
